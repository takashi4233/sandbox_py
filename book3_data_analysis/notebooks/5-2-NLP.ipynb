{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.2 NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 本節の準備\n",
    "\n",
    "```\n",
    "(pydataenv) $ pip install mecab-python3\n",
    "(pydataenv) $ pip install gensim\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.2.2 形態素解析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "吾輩\tワガハイ\t吾輩\t名詞-代名詞-一般\t\t\n",
      "は\tハ\tは\t助詞-係助詞\t\t\n",
      "猫\tネコ\t猫\t名詞-一般\t\t\n",
      "で\tデ\tだ\t助動詞\t特殊・ダ\t連用形\n",
      "ある\tアル\tある\t助動詞\t五段・ラ行アル\t基本形\n",
      "EOS\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import MeCab\n",
    "text = \"吾輩は猫である\"\n",
    "# 形態素解析の結果をChasenの形式で表示\n",
    "t = MeCab.Tagger('-Ochasen')\n",
    "result = t.parse(text)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'吾輩\\tワガハイ\\t吾輩\\t名詞-代名詞-一般\\t\\t\\nは\\tハ\\tは\\t助詞-係助詞\\t\\t\\n猫\\tネコ\\t猫\\t名詞-一般\\t\\t\\nで\\tデ\\tだ\\t助動詞\\t特殊・ダ\\t連用形\\nある\\tアル\\tある\\t助動詞\\t五段・ラ行アル\\t基本形\\nEOS\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 形態素解析の結果を確認\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['吾輩', 'ワガハイ', '吾輩', '名詞-代名詞-一般', '', '']\n",
      "['は', 'ハ', 'は', '助詞-係助詞', '', '']\n",
      "['猫', 'ネコ', '猫', '名詞-一般', '', '']\n",
      "['で', 'デ', 'だ', '助動詞', '特殊・ダ', '連用形']\n",
      "['ある', 'アル', 'ある', '助動詞', '五段・ラ行アル', '基本形']\n"
     ]
    }
   ],
   "source": [
    "# 形態素解析の結果を、改行を区切りとして行ごとに分割\n",
    "results = result.splitlines()\n",
    "# EOSの行は対象外にする\n",
    "for res in results[:-1]:\n",
    "    # タブ区切りとして各要素に分割\n",
    "    res_split = res.split('\\t')\n",
    "    print(res_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.2.3 Bag of Words (BoW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['子供', 'が', '走る'], ['車', 'が', '走る'], ['子供', 'の', '脇', 'を', '車', 'が', '走る']]\n"
     ]
    }
   ],
   "source": [
    "import MeCab\n",
    "\n",
    "documents = ['子供が走る', '車が走る', '子供の脇を車が走る']\n",
    "\n",
    "words_list = []\n",
    "\n",
    "# 形態素解析の結果をChasenの出力形式で表示\n",
    "t = MeCab.Tagger('-Ochasen')\n",
    "# 各文に形態素解析を実行\n",
    "for s in documents:\n",
    "    s_parsed = t.parse(s)\n",
    "    words_s = []\n",
    "    # 各文の形態素をリストにまとめる\n",
    "    for line in s_parsed.splitlines()[:-1]:\n",
    "        words_s.append(line.split('\\t')[0])\n",
    "    words_list.append(words_s)\n",
    "    \n",
    "print(words_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'子供': 0, 'が': 1, '走る': 2, '車': 3, 'の': 4, '脇': 5, 'を': 6}\n"
     ]
    }
   ],
   "source": [
    "# 生成する辞書\n",
    "word2int = {}\n",
    "i = 0\n",
    "# 各文書の単語のリストに対して処理を反復\n",
    "for words in words_list:\n",
    "    # 文書内の各単語に対して処理を反復\n",
    "    for word in words:\n",
    "        # 単語が辞書に含まれていなければ追加して対応する整数を割り当てる\n",
    "        if word not in word2int:\n",
    "            word2int[word] = i\n",
    "            i += 1\n",
    "print(word2int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 1 0 0 0 0]\n",
      " [0 1 1 1 0 0 0]\n",
      " [1 1 1 1 1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# BoWを計算し、文書×単語の行列を生成\n",
    "bow = np.zeros((len(words_list), len(word2int)), dtype=np.int)\n",
    "# 各行の単語を抽出し端との出現回数をカウント\n",
    "for i, words in enumerate(words_list):\n",
    "    for word in words:\n",
    "        bow[i, word2int[word]] += 1\n",
    "print(bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>子供</th>\n",
       "      <th>が</th>\n",
       "      <th>走る</th>\n",
       "      <th>車</th>\n",
       "      <th>の</th>\n",
       "      <th>脇</th>\n",
       "      <th>を</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   子供  が  走る  車  の  脇  を\n",
       "0   1  1   1  0  0  0  0\n",
       "1   0  1   1  1  0  0  0\n",
       "2   1  1   1  1  1  1  1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(bow, columns=list(word2int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(7 unique tokens: ['が', '子供', '走る', '車', 'の']...)\n"
     ]
    }
   ],
   "source": [
    "from gensim import corpora\n",
    "# 辞書を作成する\n",
    "word2int_gs = corpora.Dictionary(words_list)\n",
    "print(word2int_gs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'が': 0, '子供': 1, '走る': 2, '車': 3, 'の': 4, 'を': 5, '脇': 6}\n"
     ]
    }
   ],
   "source": [
    "# 単語と整数の対応\n",
    "print(word2int_gs.token2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1), (1, 1), (2, 1)]\n"
     ]
    }
   ],
   "source": [
    "# 1番目の文書に含まれる単語の出現回数をカウント\n",
    "print(word2int_gs.doc2bow(words_list[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 1 0 0 0 0]\n",
      " [1 0 1 1 0 0 0]\n",
      " [1 1 1 1 1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from gensim import matutils\n",
    "# Bag of Words を計算し、文書×単語の行列を生成\n",
    "bow_gs = np.array(\n",
    "                    [matutils.corpus2dense(\n",
    "                        [word2int_gs.doc2bow(words)],\n",
    "                            num_terms=len(word2int)).T[0]\n",
    "                                for words in words_list]\n",
    "            ).astype(np.int)\n",
    "print(bow_gs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>が</th>\n",
       "      <th>子供</th>\n",
       "      <th>走る</th>\n",
       "      <th>車</th>\n",
       "      <th>の</th>\n",
       "      <th>を</th>\n",
       "      <th>脇</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   が  子供  走る  車  の  を  脇\n",
       "0  1   1   1  0  0  0  0\n",
       "1  1   0   1  1  0  0  0\n",
       "2  1   1   1  1  1  1  1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pandasのデータフレームに変換\n",
    "bow_gs_df = pd.DataFrame(bow_gs, \n",
    "                                        columns=list(word2int_gs.values()))\n",
    "bow_gs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['子供 が 走る' '車 が 走る' '子供 の 脇 を 車 が 走る']\n"
     ]
    }
   ],
   "source": [
    "# 単語をスペース区切りで並べた文を生成\n",
    "words_split = np.array([' '.join(words) for words in words_list])\n",
    "print(words_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 1, 0, 1, 0],\n",
       "       [1, 0, 0, 0, 0, 1, 1],\n",
       "       [1, 1, 1, 1, 1, 1, 1]], dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Bag of Wordsを計算\n",
    "vectorizer = CountVectorizer(token_pattern=u'(?u)\\\\b\\\\w+\\\\b')\n",
    "bow_vec = vectorizer.fit_transform(words_split)\n",
    "# NumPy配列に変換\n",
    "bow_vec.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['が', 'の', 'を', '子供', '脇', '走る', '車']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.2.4 TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>が</th>\n",
       "      <th>子供</th>\n",
       "      <th>走る</th>\n",
       "      <th>車</th>\n",
       "      <th>の</th>\n",
       "      <th>を</th>\n",
       "      <th>脇</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   が  子供  走る  車  の  を  脇\n",
       "0  1   1   1  0  0  0  0\n",
       "1  1   0   1  1  0  0  0\n",
       "2  1   1   1  1  1  1  1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_gs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TFとしてBoWを使用\n",
    "tf = bow_gs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 1 0 0 0 0]\n",
      " [1 0 1 1 0 0 0]\n",
      " [1 1 1 1 1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "print(tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.28768207 0.         0.28768207 0.69314718 0.69314718\n",
      " 0.69314718]\n"
     ]
    }
   ],
   "source": [
    "# IDFを計算\n",
    "idf = np.log((bow_gs.shape[0] + 1)/\n",
    "                (np.sum(bow_gs, axis=0, keepdims=0) + 1))\n",
    "print(idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.52284231 0.67325467 0.52284231 0.         0.         0.\n",
      "  0.        ]\n",
      " [0.52284231 0.         0.52284231 0.67325467 0.         0.\n",
      "  0.        ]\n",
      " [0.26806191 0.34517852 0.26806191 0.34517852 0.45386827 0.45386827\n",
      "  0.45386827]]\n"
     ]
    }
   ],
   "source": [
    "# TF-IDFを計算\n",
    "tf_idf = tf * (idf + 1)\n",
    "tf_idf_normalized = tf_idf / np.sqrt(np.sum(tf_idf**2, axis=1, keepdims=True))\n",
    "print(tf_idf_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.52284231 0.67325467 0.52284231 0.         0.         0.\n",
      "  0.        ]\n",
      " [0.52284231 0.         0.52284231 0.67325467 0.         0.\n",
      "  0.        ]\n",
      " [0.26806191 0.34517852 0.26806191 0.34517852 0.45386827 0.45386827\n",
      "  0.45386827]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "# TfidfTransformerクラスをインスタンス化\n",
    "tfidf = TfidfTransformer(use_idf=True, norm='l2', smooth_idf=True)\n",
    "# TF-IDFを算出\n",
    "print(tfidf.fit_transform(bow_gs).toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.2.5 極性判定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import urllib.request\n",
    "\n",
    "# 青空文庫の「吾輩は猫である」のファイルをダウンロード\n",
    "urllib.request.urlretrieve('https://www.aozora.gr.jp/cards/000148/files/789_ruby_5639.zip', '789_ruby_5639.zip')\n",
    "\n",
    "# zipファイルを解凍しデータを読み込む\n",
    "with zipfile.ZipFile('789_ruby_5639.zip', 'r') as zipf:\n",
    "    data = zipf.read('wagahaiwa_nekodearu.txt')  # bytesを変換\n",
    "text = data.decode('shift_jis')  # shift-jisに変換"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['一吾輩は猫である', '名前はまだ無い', 'どこで生れたかとんと見当がつかぬ', '何でも薄暗いじめじめした所でニャーニャー泣いていた事だけは記憶している', '吾輩はここで始めて人間というものを見た']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "# ルビ　, 注釈, 改行コードを除去\n",
    "text = re.split(r'\\-{5,}', text)[2]\n",
    "text = text.split('底本: ')[0]\n",
    "text = re.sub(r'《.+?》', '', text)\n",
    "text = re.sub(r'［＃.+?］', '', text)\n",
    "text = text.strip()\n",
    "# 空白文字を除去\n",
    "text = text.replace('\\u3000', '')\n",
    "# 改行コードを除去\n",
    "text = text.replace('\\r', '').replace('\\n', '')\n",
    "# 「。」を区切り文字として分割\n",
    "sentences = text.split('。')\n",
    "print(sentences[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['一', '吾輩', 'は', '猫', 'だ', 'ある'], ['名前', 'は', 'まだ', '無い'], ['どこ', 'で', '生れる', 'た', 'か', 'とんと', '見当', 'が', 'つく', 'ぬ'], ['何', 'でも', '薄暗い', 'じめじめ', 'する', 'た', '所', 'で', 'ニャーニャー', '泣く', 'て', 'いた事', 'だけ', 'は', '記憶', 'する', 'て', 'いる'], ['吾輩', 'は', 'ここ', 'で', '始める', 'て', '人間', 'という', 'もの', 'を', '見る', 'た'], ['しかも', 'あと', 'で', '聞く', 'と', 'それ', 'は', '書生', 'という', '人間', '中', 'で', '一番', '｜', '獰悪', 'だ', '種族', 'だ', 'ある', 'た', 'そう', 'だ'], ['この', '書生', 'という', 'の', 'は', '時々', '我々', 'を', '捕える', 'て', '煮る', 'て', '食う', 'という', '話', 'だ', 'ある'], ['しかし', 'その', '当時', 'は', '何', 'という', '考', 'も', 'ない', 'た', 'から', '別段', '恐い', 'いとも', '思う', 'ない', 'た'], ['ただ', '彼', 'の', '掌', 'に', '載せる', 'られる', 'て', 'スー', 'と', '持ち上げる', 'られる', 'た', '時', '何だか', 'フワフワ', 'する', 'た', '感じ', 'が', 'ある', 'た', 'ばかり', 'だ', 'ある'], ['掌', 'の', '上', 'で', '少し', '落ちつく', 'て', '書生', 'の', '顔', 'を', '見る', 'た', 'の', 'が', 'いわゆる', '人間', 'という', 'もの', 'の', '見る', '始', 'だ', 'ある', 'う']]\n"
     ]
    }
   ],
   "source": [
    "import MeCab\n",
    "\n",
    "words_list = []\n",
    "\n",
    "# MeCabにより形態素解析を実行\n",
    "t = MeCab.Tagger('-Ochasen')\n",
    "# 各文に形態素解析を実行(最後の要素は単語がないため除外)\n",
    "for sentence in sentences[:-1]:\n",
    "    sentence_parsed =t.parse(sentence)\n",
    "    word_s = []\n",
    "    # 各文書に現れる単語のリストに対して処理を反復\n",
    "    for line in sentence_parsed.splitlines()[:-1]:\n",
    "        word_s.append(line.split('\\t')[2])\n",
    "    words_list.append(word_s)\n",
    "\n",
    "print(words_list[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('wago.121808.pn', <http.client.HTTPMessage at 0x7fc240ad12b0>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urllib.request.urlretrieve('http://www.cl.ecei.tohoku.ac.jp/resources/sent_lex/wago.121808.pn', 'wago.121808.pn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ネガ（経験）</td>\n",
       "      <td>あがく</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ネガ（経験）</td>\n",
       "      <td>あきらめる</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ネガ（経験）</td>\n",
       "      <td>あきる</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0      1\n",
       "0  ネガ（経験）    あがく\n",
       "1  ネガ（経験）  あきらめる\n",
       "2  ネガ（経験）    あきる"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wago = pd.read_csv('wago.121808.pn', header=None, sep='\\t')\n",
    "wago.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#　単語とスコアを対応させる辞書を作成\n",
    "word2score = {}\n",
    "values = {'ポジ（経験）': 1, 'ポジ（評価）': 1, 'ネガ（経験）': -1, 'ネガ（評価）': -1}\n",
    "for word, label in zip(wago.loc[:, 1], wago.loc[:, 0]):\n",
    "    word2score[word] = values[label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('あがく', -1), ('あきらめる', -1), ('あきる', -1)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(word2score.items())[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "for words in words_list:\n",
    "    score = 0\n",
    "    #  単語が辞書に現れていればスコアを加算\n",
    "    for word in words:\n",
    "        if word in word2score:\n",
    "            score += word2score[word]\n",
    "    scores.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>一吾輩は猫である</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>名前はまだ無い</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>どこで生れたかとんと見当がつかぬ</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>何でも薄暗いじめじめした所でニャーニャー泣いていた事だけは記憶している</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>吾輩はここで始めて人間というものを見た</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              sentence  score\n",
       "0                             一吾輩は猫である      0\n",
       "1                              名前はまだ無い      0\n",
       "2                     どこで生れたかとんと見当がつかぬ      0\n",
       "3  何でも薄暗いじめじめした所でニャーニャー泣いていた事だけは記憶している     -1\n",
       "4                  吾輩はここで始めて人間というものを見た      0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df = pd.DataFrame({'sentence': sentences[:-1], 'score': scores}, columns=['sentence', 'score'])\n",
    "scores_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>「厭きっぽいのじゃない薬が利かんのだ」「それだってせんだってじゅうは大変によく利くよく利くと...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1428</th>\n",
       "      <td>四百六十五行から、四百七十三行を御覧になると分ります」「希臘語｜云々はよした方がいい、さも希...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3860</th>\n",
       "      <td>美しい？美しくても構わんから、美しい獣と見做せばいいのである</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5380</th>\n",
       "      <td>精神の修養を主張するところなぞは大に敬服していい」「敬服していいかね</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6768</th>\n",
       "      <td>これがぬすみ食をするとか、贋札を造るとか云うなら、まだ始末がいいが、音曲は人に隠しちゃ出来な...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sentence  score\n",
       "453   「厭きっぽいのじゃない薬が利かんのだ」「それだってせんだってじゅうは大変によく利くよく利くと...      5\n",
       "1428  四百六十五行から、四百七十三行を御覧になると分ります」「希臘語｜云々はよした方がいい、さも希...      5\n",
       "3860                     美しい？美しくても構わんから、美しい獣と見做せばいいのである      4\n",
       "5380                 精神の修養を主張するところなぞは大に敬服していい」「敬服していいかね      4\n",
       "6768  これがぬすみ食をするとか、贋札を造るとか云うなら、まだ始末がいいが、音曲は人に隠しちゃ出来な...      3"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# スコアの降順に並び返る\n",
    "scores_df_sorted = scores_df.sort_values('score', ascending=False)\n",
    "# スコアの高い文書5件を抽出\n",
    "scores_df_sorted.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2045</th>\n",
       "      <td>何か怒っているかも知れんが、怒るのは向が悪るいからで、先方がおとなしくしてさえいれば一身上の...</td>\n",
       "      <td>-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6618</th>\n",
       "      <td>どうもいつまで行っても柿ばかり食ってて際限がないね」「私もじれったくてね」「君より聞いてる方...</td>\n",
       "      <td>-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3783</th>\n",
       "      <td>こんな、しつこい、毒悪な、ねちねちした、執念深い奴は大嫌だ</td>\n",
       "      <td>-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7098</th>\n",
       "      <td>向うがあやまるなら特別、私の方ではそんな慾はありません」「警察が君にあやまれと命じたらどうで...</td>\n",
       "      <td>-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6687</th>\n",
       "      <td>「古人を待つ身につらき置炬燵と云われた事があるからね、また待たるる身より待つ身はつらいともあ...</td>\n",
       "      <td>-5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sentence  score\n",
       "2045  何か怒っているかも知れんが、怒るのは向が悪るいからで、先方がおとなしくしてさえいれば一身上の...     -3\n",
       "6618  どうもいつまで行っても柿ばかり食ってて際限がないね」「私もじれったくてね」「君より聞いてる方...     -4\n",
       "3783                      こんな、しつこい、毒悪な、ねちねちした、執念深い奴は大嫌だ     -4\n",
       "7098  向うがあやまるなら特別、私の方ではそんな慾はありません」「警察が君にあやまれと命じたらどうで...     -4\n",
       "6687  「古人を待つ身につらき置炬燵と云われた事があるからね、また待たるる身より待つ身はつらいともあ...     -5"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# スコアの低い5件を抽出\n",
    "scores_df_sorted.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
